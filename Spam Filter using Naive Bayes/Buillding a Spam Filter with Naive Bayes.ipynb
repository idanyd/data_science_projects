{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keeping it Clean: Building a Spam Filter with Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introduction](#intorduction)\n",
    "* [Goal](#goal)\n",
    "* [Summary](#summary)\n",
    "* [The Data](#the_data)\n",
    "* [Training and Test Set](#training_and_test_set)\n",
    "* [Data Cleaning](#data_cleaning)\n",
    "  * [Letter Case and Punctuation](#letter_case_and_punctuation)\n",
    "  * [Creating the Vocabulary](#creating_the_vocabulary)\n",
    "  * [The Final Training Set](#final_training_set)\n",
    "* [Training the Model](#training_the_model)\n",
    "  * [Calculating Constants First](#calculating_constants_first)\n",
    "  * [Calculating Parameters](#calculating_parameters)\n",
    "* [Classifying A New Message](#classifying_a_new_message)\n",
    "* [Measuring the Spam Filter's Accuracy](#measuring_the_spam_filters_accuracy)\n",
    "* [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction  <a name=\"introduction\"></a>\n",
    "\n",
    "The Naïve Bayes algorithm is a simple technique for constructing classifiers.\n",
    "In this guided project, we're going to study the practical side of the algorithm by building a spam filter for SMS messages.\n",
    "Naïve Bayes is especially effective for text classification tasks like spam filtering because it handles high-dimensional feature spaces well and performs surprisingly well even with its 'naïve' assumption of feature independence. The algorithm is also computationally efficient and requires relatively little training data to achieve good results, making it ideal for processing short text messages. Additionally, its probabilistic nature allows us to easily interpret and understand why certain messages are classified as spam or legitimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal  <a name=\"goal\"></a>\n",
    "\n",
    "We aim to write a program that will classify new SMS messages as spam or ham with an accuracy greater than 80%.\n",
    "We'll calculate this accuracy by comparing our model's predictions against known classifications, determining the percentage of messages where our prediction matches the original label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary  <a name=\"summary\"></a>\n",
    "\n",
    "We managed to create a spam filter with an accuracy of 98.7%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data <a name=\"the_data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was put together by Tiago A. Almeida and José María Gómez Hidalgo, and it can be downloaded from the [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). You can also download the dataset directly from [this link](https://dq-content.s3.amazonaws.com/433/SMSSpamCollection). The data collection process is described in more details on [this page](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/#composition), where you can also find some of the authors' papers.\n",
    "\n",
    "We'll start by reading the dataset and printing some initial data about it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows and columns in the dataset:\n",
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from numpy import prod\n",
    "\n",
    "collection = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "\n",
    "print(\"The number of rows and columns in the dataset:\")\n",
    "print(collection.shape)\n",
    "\n",
    "collection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very simple dataset. It's composed of only two columns - the contents of the message (`SMS`) and a classification (`Label`. `spam` for spam messages, `ham` for legitimate ones). About 87% of the messages are legitimate, and the remaining 13% is spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Set <a name=\"training_and_test_set\"></a>\n",
    "\n",
    "Before building and training our spam filter, we should split our dataset into a training set and a test set. The **training set** is used to \"train\" the computer how to classify messages, and the **test set** is used to test how good the spam filter is with classifying new messages.\n",
    "\n",
    "We're going to keep 80% of our dataset for training, and 20% for testing (we want to train the algorithm on as much data as possible, but we also want to have enough test data). The dataset has 5,572 messages, which means that:\n",
    "\n",
    "* The training set will have 4,458 messages (about 80% of the dataset).\n",
    "* The test set will have 1,114 messages (about 20% of the dataset).\n",
    "\n",
    "Since all messages in the dataset are already classified, the way to test our algorithm is by running it on the test set and comparing its classifications against the actual classification.\n",
    "As mentioned above, our goal is to create a classifier with an accuracy greater than 80%, so when the algorithm correctly specifies over 80% of the test set we'll consider the goal reached.\n",
    "\n",
    "To create both subsets we'll start by randomizing the entire dataset to ensure that spam and ham messages are spread properly throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomized_collection = collection.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can safely split the dataset into a training and a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = randomized_collection.iloc[:4458].copy().reset_index(drop=True)\n",
    "test_set = randomized_collection.iloc[4458:].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Division of ham and spam messages in the Training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     0.86541\n",
       "spam    0.13459\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Division of ham and spam messages in the Test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     0.868043\n",
       "spam    0.131957\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, both sets have a similar ham/spam percentage. The difference between them is negligible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning <a name=\"data_cleaning\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Letter Case and Punctuation <a name=\"letter_case_and_punctuation\"></a>\n",
    "\n",
    "Before we can use the training we'll need to perform a bit of data cleaning to bring the data in a format that will allow us to easily extract all the information we need.\n",
    "To make calculations easiter we want to add columns to the data set (one per word in the vocabulary) with counters how many times each word appeared in each message.\n",
    "\n",
    "Let's begin the data cleaning process by removing the punctiation and bringing all the words to lower case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "training_set['clean_SMS'] = training_set['SMS'].str.replace('\\W', ' ').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                            yep, by the pretty sculpture\n",
       "1           yes, princess. are you going to make me moan?\n",
       "2                              welp apparently he retired\n",
       "3                                                 havent.\n",
       "4       i forgot 2 ask ü all smth.. there's a card on ...\n",
       "                              ...                        \n",
       "4453    sorry, i'll call later in meeting any thing re...\n",
       "4454    babe! i fucking love you too !! you know? fuck...\n",
       "4455    u've been selected to stay in 1 of 250 top bri...\n",
       "4456    hello my boytoy ... geeee i miss you already a...\n",
       "4457                             wherre's my boytoy ? :-(\n",
       "Name: clean_SMS, Length: 4458, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['clean_SMS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Vocabulary <a name=\"creating_the_vocabulary\"></a>\n",
    "\n",
    "To create a column for each word in our vocabulary, we'll need to create a vocabulary. We'll do that by reading each SMS message and adding each word to a `vocabulary` set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split each label into words, then iterate over each list of words\n",
    "# and add all the words in that list to the vocabulary\n",
    "training_set['clean_SMS'] = training_set['clean_SMS'].str.split()\n",
    "vocabulary = set([word for words in training_set['clean_SMS'] for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11860"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 7,783 unique words in our vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Final Training Set <a name=\"final_training_set\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Now it's time to create the words columns (one column for every word in our dictionary). We'll do that by first creating a word count dictionary, then building a dataframe using that dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create an dictionary of lists containing zeros. Each list will match a single word in our vocabulary\n",
    "# and its length will be the size of our training set\n",
    "word_counts_per_sms = {unique_word: [0] * len(training_set['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "# Now we populate the lists\n",
    "for index, sms in enumerate(training_set['clean_SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe from the dictionary\n",
    "word_counts = pd.DataFrame(word_counts_per_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate with the training set, to get the Label, SMS and clean_SMS columns\n",
    "word_counts = pd.concat([training_set, word_counts], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>clean_SMS</th>\n",
       "      <th>much!!i</th>\n",
       "      <th>lane</th>\n",
       "      <th>me....</th>\n",
       "      <th>said</th>\n",
       "      <th>unique&amp;i</th>\n",
       "      <th>shoppin</th>\n",
       "      <th>include</th>\n",
       "      <th>...</th>\n",
       "      <th>sweetie</th>\n",
       "      <th>next.</th>\n",
       "      <th>tears</th>\n",
       "      <th>college?</th>\n",
       "      <th>2yr</th>\n",
       "      <th>5years</th>\n",
       "      <th>will!</th>\n",
       "      <th>hurried</th>\n",
       "      <th>vote.</th>\n",
       "      <th>:-)only</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "      <td>[yep,, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "      <td>[yes,, princess., are, you, going, to, make, m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "      <td>[havent.]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth.., there's, a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11863 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  \\\n",
       "0   ham                       Yep, by the pretty sculpture   \n",
       "1   ham      Yes, princess. Are you going to make me moan?   \n",
       "2   ham                         Welp apparently he retired   \n",
       "3   ham                                            Havent.   \n",
       "4   ham  I forgot 2 ask ü all smth.. There's a card on ...   \n",
       "\n",
       "                                           clean_SMS  much!!i  lane  me....  \\\n",
       "0                 [yep,, by, the, pretty, sculpture]        0     0       0   \n",
       "1  [yes,, princess., are, you, going, to, make, m...        0     0       0   \n",
       "2                    [welp, apparently, he, retired]        0     0       0   \n",
       "3                                          [havent.]        0     0       0   \n",
       "4  [i, forgot, 2, ask, ü, all, smth.., there's, a...        0     0       0   \n",
       "\n",
       "   said  unique&i  shoppin  include  ...  sweetie  next.  tears  college?  \\\n",
       "0     0         0        0        0  ...        0      0      0         0   \n",
       "1     0         0        0        0  ...        0      0      0         0   \n",
       "2     0         0        0        0  ...        0      0      0         0   \n",
       "3     0         0        0        0  ...        0      0      0         0   \n",
       "4     0         0        0        0  ...        0      0      0         0   \n",
       "\n",
       "   2yr  5years  will!  hurried  vote.  :-)only  \n",
       "0    0       0      0        0      0        0  \n",
       "1    0       0      0        0      0        0  \n",
       "2    0       0      0        0      0        0  \n",
       "3    0       0      0        0      0        0  \n",
       "4    0       0      0        0      0        0  \n",
       "\n",
       "[5 rows x 11863 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model <a name=\"training_the_model\"></a>\n",
    "\n",
    "Now that we're done with data cleaning and have a training set to work with, we can begin creating the spam filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Calculating Constants First <a name=\"calculating_constants_first\"></a>\n",
    "\n",
    "the Naïve Bayes algorithm will need to know the probability values of the two equations below to be able to classify new messages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P \\left(Spam \\middle| \\ w_1, w_2, ..., w_n\\right) \\propto P(Spam)\\cdot\\prod_{i=1}^{n} P\\left( w_i \\middle| \\, Spam \\right)$$\n",
    "\n",
    "$$P \\left(Ham \\middle| \\ w_1, w_2, ..., w_n\\right) \\propto P(Ham)\\cdot\\prod_{i=1}^{n} P\\left( w_i \\middle| \\, Ham \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, to calculate P(w<sub>i</sub>|Spam) and P(w<sub>i</sub>|Ham) inside the formulas above, we need to use these equations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\dfrac{N_{w_i|Spam}+\\alpha}{N_{Spam}+\\alpha \\cdot N_{Vocabulary}\n",
    "}$$\n",
    "\n",
    "\n",
    "$$\\dfrac{N_{w_i|Ham}+\\alpha}{N_{Ham}+\\alpha \\cdot N_{Vocabulary}\n",
    "}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by calculating P(Spam), P(Ham), N<sub>Spam</sub>, N<sub>Ham</sub> and N<sub>Vocabulary</sub> from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam): 0.135\n",
      "P(Ham): 0.865\n",
      "N(Spam): 14257\n",
      "N(Ham): 55376\n",
      "N(Vocabulary): 11860\n"
     ]
    }
   ],
   "source": [
    "# P(Spam) and P(Ham)\n",
    "p_spam = word_counts['Label'].value_counts(normalize=True)['spam']\n",
    "p_ham = 1 - p_spam\n",
    "\n",
    "# N(Spam): The number of words in all spam messages\n",
    "n_spam = word_counts[word_counts['Label'] == 'spam']['clean_SMS'].apply(len).sum()\n",
    "\n",
    "# N(Ham): The number of words in all ham messages\n",
    "n_ham = word_counts[word_counts['Label'] == 'ham']['clean_SMS'].apply(len).sum()\n",
    "\n",
    "# N(Vocabulary): The size of our vocabulary\n",
    "n_vocab = len(vocabulary)\n",
    "\n",
    "# Set Laplace smoothing alpha as 1\n",
    "alpha = 1\n",
    "\n",
    "print(\"P(Spam): {:.3}\".format(p_spam))\n",
    "print(\"P(Ham): {:.3}\".format(p_ham))\n",
    "print(\"N(Spam): {}\".format(n_spam))\n",
    "print(\"N(Ham): {}\".format(n_ham))\n",
    "print(\"N(Vocabulary): {}\".format(n_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Parameters <a name=\"calculating_parameters\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To same time during the classification process we'll calculate the probability values for each word in our vocabulary ahead of time. That way we can use the calculated value instead of recalculating for each new message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Isolate the spam and ham messages\n",
    "spam_word_count = word_counts[word_counts['Label'] == 'spam'].copy()\n",
    "ham_word_count = word_counts[word_counts['Label'] == 'ham'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Populate two dictionaries - one for spam words and the other for ham words\n",
    "spam_den = n_spam + alpha * n_vocab\n",
    "ham_den = n_ham + alpha * n_vocab\n",
    "\n",
    "spam_params = {word:(spam_word_count[word].sum() + alpha) / spam_den for word in vocabulary}\n",
    "ham_params = {word:(ham_word_count[word].sum() + alpha) / ham_den for word in vocabulary}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying A New Message <a name=\"classifying_a_new_message\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've calculated all the constants and parameters we need, we can start creating the spam filter. The spam filter can be understood as a function that:\n",
    "\n",
    "* Takes in as input a new message (w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>)\n",
    "* Calculates P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) and P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>)\n",
    "* Compares the values of P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) and P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>), and:\n",
    "* If P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) > P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>), then the message is classified as ham.\n",
    "* If P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) < P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>), then the message is classified as spam.\n",
    "* If P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) = P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>), then the algorithm may request human help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def classify(message:str, print_output = True) -> str:\n",
    "    \"\"\"\n",
    "    Classify a message as spam or ham using Naive Bayes classification.\n",
    "    \n",
    "    Processes the input message by removing punctuation, converting it to lowercase,\n",
    "    and tokenizing it into words. Then applies Naive Bayes classification using\n",
    "    pre-calculated word probabilities to determine if the message is spam or ham.\n",
    "    \n",
    "    Args:\n",
    "       message (str): The text message to classify\n",
    "       print_output (bool, optional): Whether to print probability details. Defaults to True\n",
    "       \n",
    "    Returns:\n",
    "       str: Classification result - either 'spam', 'ham', or 'undecided'\n",
    "       \n",
    "    Examples:\n",
    "       >>> classify(\"Win a free iPhone!\")\n",
    "       Classification: spam\n",
    "       'spam'\n",
    "       \n",
    "       >>> classify(\"Meeting at 3pm tomorrow\", print_output=False)\n",
    "       'ham'\n",
    "    \n",
    "    Notes:\n",
    "       - Uses global variables:\n",
    "           * p_spam: Prior probability of spam\n",
    "           * p_ham: Prior probability of ham\n",
    "           * spam_params: Dictionary of word probabilities in spam messages\n",
    "           * ham_params: Dictionary of word probabilities in ham messages\n",
    "       - Text preprocessing steps:\n",
    "           1. Removes all non-word characters\n",
    "           2. Converts to lowercase\n",
    "           3. Splits into individual words\n",
    "       - Uses product of word probabilities following Naive Bayes assumption\n",
    "       - Returns 'undecided' if spam and ham probabilities are equal\n",
    "       \n",
    "    Dependencies:\n",
    "       - re: For regular expression text preprocessing\n",
    "       - numpy.prod: For calculating product of probabilities\n",
    "       \n",
    "    See Also:\n",
    "       numpy.prod: Used to multiply probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    message = (re.sub('\\W', ' ', message) # Remove punctuations\n",
    "              .lower() # Move to lowercase\n",
    "              .split() # separate into words\n",
    "              )\n",
    "\n",
    "    # Calculate the odds of the message being spam or ham\n",
    "    p_spam_given_message = p_spam * prod([spam_params[word]\n",
    "                                          for word in message\n",
    "                                          if word in spam_params])\n",
    "    \n",
    "    p_ham_given_message = p_ham * prod([ham_params[word]\n",
    "                                        for word in message\n",
    "                                        if word in ham_params])\n",
    "\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        result = 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        result = 'spam'\n",
    "    else:\n",
    "        result = 'undecided'\n",
    "    \n",
    "    if print_output:\n",
    "        print('P(Spam|message):', p_spam_given_message)\n",
    "        print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "        print('Classification: {}'.format(result))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our code on two messages. An obvious spam and an obvious ham:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.168002363207846e-26\n",
      "P(Ham|message): 6.088544142463393e-28\n",
      "Classification: spam\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.2342992839679443e-26\n",
      "P(Ham|message): 8.376346103813855e-22\n",
      "Classification: ham\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, looks like it's working fine. Now it's time to measure the filter's accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the Spam Filter's Accuracy <a name=\"measuring_the_spam_filters_accuracy\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Run the filter on the test set\n",
    "test_set['predicted'] = test_set['SMS'].apply(classify, print_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all that's lef tis to compare the predicted values with the actual values to measure how good our spam filter is with classifying new messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test_set['correct'] = test_set['Label'] == test_set['predicted']\n",
    "\n",
    "# Accuracy is measured by dividing the number of correct predictions by the total number of messages\n",
    "accuracy = test_set['correct'].sum() / test_set.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's our accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.8%\n"
     ]
    }
   ],
   "source": [
    "print(f\"{accuracy*100:.03}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing. Our goal was to create a filter with above 80% success rate, and our filter has a success rate of 97.8%. Meaning only 13 messages out of 1,000 will be misclassified.\n",
    "\n",
    "But let's look at some more metrics to better assess our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 94.3%\n",
      "Recall = 89.8%\n",
      "F1 Score = 92.0%\n"
     ]
    }
   ],
   "source": [
    "precision = test_set[(test_set['predicted'] == 'spam') & (test_set['Label'] == 'spam')]['predicted'].count() / test_set[test_set['predicted'] == 'spam']['predicted'].count()\n",
    "recall = test_set[(test_set['predicted'] == 'spam') & (test_set['Label'] == 'spam')]['predicted'].count() / test_set[test_set['Label'] == 'spam']['predicted'].count()\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"Precision = {precision*100:.03}%\")\n",
    "print(f\"Recall = {recall*100:.03}%\")\n",
    "print(f\"F1 Score = {f1_score*100:0.3}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(df: pd.DataFrame, col1: str, col2: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a dataframe with at least\n",
    "    two categorical columns, create a \n",
    "    confusion matrix of the count of the columns\n",
    "    cross-counts\n",
    "    \n",
    "    Example:\n",
    "    \n",
    "    confusion_matrix(test_df, 'predicted', 'actual')\n",
    "    \"\"\"\n",
    "    return (\n",
    "            df\n",
    "            .groupby([col1, col2])\n",
    "            .size()\n",
    "            .unstack(fill_value=0)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the model's confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Label</th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>958</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>8</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undecided</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Label      ham  spam\n",
       "predicted           \n",
       "ham        958    15\n",
       "spam         8   132\n",
       "undecided    1     0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(test_set, 'predicted', 'Label')\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show strong overall performance but with some interesting nuances:\n",
    "\n",
    "1. Precision of 94.3% indicates that when our model predicts spam, it's right about 94 times out of 100. The relatively high precision is crucial for a spam filter, as false positives (marking legitimate emails as spam) can be particularly problematic for users.\n",
    "\n",
    "2. Recall of 89.8% shows we're catching about 90% of all actual spam messages. Looking at the confusion matrix, we missed 15 spam messages (labelled them as ham) out of the 147 total spam messages.\n",
    "\n",
    "3.  The confusion matrix reveals:\n",
    "    * Very few false positives: only 8 ham messages were incorrectly labelled as spam\n",
    "    * A slightly higher number of false negatives: 15 spam messages got through\n",
    "    * One message remained \"undecided,\" which is better than making a wrong classification\n",
    "    * The model handled ham messages particularly well, correctly identifying 958 out of 967 (99.1%)\n",
    "\n",
    "Key takeaway: The model is performing well but appears to be slightly conservative in its spam classification, preferring to let a spam message through rather than risk blocking legitimate messages. This is generally a good approach for a spam filter, as users typically prefer to receive occasional spam rather than miss important legitimate messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion <a name=\"conclusion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used The Naïve Bayes algorithm to build a spam filter, achieving strong overall performance with 94.3% precision and 89.8% recall.\n",
    "The confusion matrix reveals that our model is notably conservative in its classifications, preferring to let a spam message through rather than risk blocking legitimate messages. \n",
    "While this conservative approach aligns well with user preferences — most people would rather receive occasional spam than miss important legitimate messages — there's still room for improvement.\n",
    "\n",
    "Several promising avenues could enhance our system further. We could explore more sophisticated feature extraction methods, such as incorporating word embeddings or n-grams to capture contextual relationships between words. This might help catch the small amount of spam messages that slipped through while maintaining our strong precision.\n",
    "We might also experiment with different algorithms like Support Vector Machines or modern deep learning approaches to compare their performance against our Naive Bayes implementation.\n",
    "\n",
    "The dataset itself presents opportunities for improvement. Expanding it with more recent spam examples would help the model stay current with evolving spam tactics. Additionally, collecting messages in multiple languages or from different communication platforms would make the classifier more robust and widely applicable.\n",
    "\n",
    "Finally, we could enhance the preprocessing stage by implementing more nuanced text cleaning methods, such as lemmatization instead of basic stemming, or by preserving certain structural features of messages that might be indicative of spam. While our current model performs admirably, with an F1 score of 92%, these refinements could lead to an even more reliable and versatile spam detection system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
